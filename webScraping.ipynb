{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for scraping data from HTML \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#for pulling , pushing and authenticating \n",
    "import requests\n",
    "\n",
    "#for carrying out regular expressions operations\n",
    "import re\n",
    "\n",
    "import operator\n",
    "\n",
    "import json\n",
    "\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get words\n",
    "def getWords(link):\n",
    "    list_of_words = []\n",
    "    \n",
    "    #data\n",
    "    words = requests.get(link)\n",
    "    #converting to plain text\n",
    "    ptext = words.text\n",
    "    #converting to lxml format\n",
    "    soup = BeautifulSoup(ptext,'lxml')\n",
    "    \n",
    "    #get words from paragraphs\n",
    "    for text in soup.findAll('p'):\n",
    "        if text.text is None:\n",
    "            continue\n",
    "        \n",
    "        content = text.text\n",
    "        \n",
    "        #to lowercase\n",
    "        words_lowercase = content.lower().split()\n",
    "        \n",
    "        #word-wise\n",
    "        for each_word in words_lowercase:\n",
    "            clean_word = cleanWord(each_word)\n",
    "            if(len(clean_word)>0):\n",
    "                list_of_words.append(clean_word)\n",
    "                \n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to clean words using regex\n",
    "def cleanWord(words):\n",
    "    clean_words = re.sub('[^A-Za-z]+','',words)\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing stop Words\n",
    "def remove_stopwords(word_list):\n",
    "    stop_words = get_stop_words('en')\n",
    "    \n",
    "    temp = []\n",
    "    for i,j in word_list:\n",
    "        if i not in stop_words:\n",
    "            temp.append([i,j])\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequencyTable(word_list):\n",
    "    #word count\n",
    "    word_count = {}\n",
    "    for word in word_list:\n",
    "        #index is the word\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter term term to be searched in WIKI:   shah rukh khan\n",
      "\n",
      " DO you want to remove the stop words? 'yes' or 'no' :   yes\n",
      "| Word        |   Frequency |   Frequency Percentage |\n",
      "|-------------+-------------+------------------------|\n",
      "| khan        |         139 |                 3.5577 |\n",
      "| film        |          66 |                 1.6893 |\n",
      "| films       |          30 |                 0.7679 |\n",
      "| india       |          29 |                 0.7423 |\n",
      "| indian      |          28 |                 0.7167 |\n",
      "| performance |          27 |                 0.6911 |\n",
      "| khans       |          27 |                 0.6911 |\n",
      "| bollywood   |          26 |                 0.6655 |\n",
      "| best        |          25 |                 0.6399 |\n",
      "| role        |          25 |                 0.6399 |\n",
      "| filmfare    |          24 |                 0.6143 |\n",
      "| actor       |          21 |                 0.5375 |\n",
      "| million     |          21 |                 0.5375 |\n",
      "| first       |          21 |                 0.5375 |\n",
      "| award       |          20 |                 0.5119 |\n",
      "| year        |          20 |                 0.5119 |\n",
      "| one         |          19 |                 0.4863 |\n",
      "| time        |          17 |                 0.4351 |\n",
      "| us          |          17 |                 0.4351 |\n",
      "| became      |          16 |                 0.4095 |\n"
     ]
    }
   ],
   "source": [
    "api_link = \"https://en.wikipedia.org/w/api.php?format=json&action=query&list=search&srsearch=\"\n",
    "website_link = \"https://en.wikipedia.org/wiki/\"\n",
    "\n",
    "if (len(sys.argv)<2):\n",
    "    print \"Enter valid string\"\n",
    "    exit()\n",
    "\n",
    "#get the search word\n",
    "query = raw_input(\"\\n Enter term term to be searched in WIKI:   \")\n",
    "\n",
    "yes_no = raw_input(\"\\n DO you want to remove the stop words? 'yes' or 'no' :   \")\n",
    "if (len(yes_no)>2):\n",
    "    search_mode = True\n",
    "else:\n",
    "    search_mode = False\n",
    "    \n",
    "#URL\n",
    "url = api_link + query\n",
    "\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.content.decode(\"utf-8\"))\n",
    "    \n",
    "    #format data\n",
    "    page_tag = data['query']['search'][0]['title']\n",
    "    \n",
    "    #recreate new URL\n",
    "    new_url = website_link + page_tag\n",
    "    word_list_from_page = getWords(new_url)\n",
    "    \n",
    "    #get word counts\n",
    "    page_word_count = frequencyTable(word_list_from_page)\n",
    "    #sort the word freq list\n",
    "    sorted_list = sorted(page_word_count.items(),key = operator.itemgetter(1),reverse = True)\n",
    "    \n",
    "    #remove stop words\n",
    "    if (search_mode):\n",
    "        sorted_list = remove_stopwords(sorted_list)\n",
    "        \n",
    "    total_words_sum = 0\n",
    "    for key,value in sorted_list:\n",
    "        total_words_sum = total_words_sum + value\n",
    "    \n",
    "    #get top 20 words\n",
    "    if len(sorted_list) > 20:\n",
    "        sorted_list = sorted_list[:20]\n",
    "        \n",
    "    final_list = []\n",
    "    for key,value in sorted_list:\n",
    "        percent_value = float(value*100)/total_words_sum\n",
    "        final_list.append([key,value,round(percent_value,4)])\n",
    "        \n",
    "    print_headers =['Word','Frequency', 'Frequency Percentage']\n",
    "    \n",
    "    #print the table with tabulate\n",
    "    print(tabulate(final_list, headers=print_headers, tablefmt='orgtbl'))\n",
    "    \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"The server didn't respond. Please, try again later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print page_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print website_link"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
